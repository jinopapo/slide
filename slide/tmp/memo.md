---
marp: true
theme: myTheme
---

<!-- _class: lead -->
# AIのリスクとガバナンス

---
<!--
このスライドの全体像を示してほしい
-->

---
<!--
- AIは非連続的な変化をもたらす技術
- AIの進歩に対して周辺技術や倫理観が追いついてない
- リスクと恩恵のトレードオフを決める必要がある
- 技術的な判断ではなく、経営判断
- どんなリスクがあり、そのリスクを受容できるかを経営層が判断する必要がある
  
-->
## AIガバナンス

---
<!--
これから話す内容の全体像を伝えるスライド
今からLLMベンダー、AIサービス、MCPの3つのレイヤーごとにリスクの説明をすることがわかるようにしたい
-->
## AIのリスク

---
<!--
LLMベンダーをつかうということはLLMベンダーにデータを送ることになる
LLMベンダーがどのようにデータを扱うかによってリスクが発生する
学習に使われると不特定多数に情報漏えいする可能性がある
データを送った時点でベンダー内部で閲覧される可能性
どういうデータを送ってよいかを決める必要がある
信頼できるベンダーを選ぶことも重要
-->
## LLMベンダーのリスク

---
<!--
LLMを使ったサービス全般を指している
claude codeのようなエージェントもそうだし、chatgptのような単純なチャットサービスも含む
-->
## AIサービスとは

---
<!--
AIサービスは理論上何でもできる
開発エージェントで言えば、理論上PCのすべての情報にアクセスできる
もっと言えば社内ネットワークにもアクセスできる
最悪の場合何が起こるのか、そのリスクを監視できるのかを考える必要がある
LLMベンダー以上に信頼できるサービスを選ぶことが重要になる
-->
## AIサービスのリスク
---
<!--
MCPは発展途上
悪意のあるMCPとエージェントと組み合わさると実質ウイルスをインストールしたのと同じ状態になる可能性がある
例えば、MCPが外部と通信して情報を抜き取るような動作をする可能性
もしくは特定のディレクトリを削除するようなプロンプトが含まれたmcpなど
エージェント自体のセキュリティも重要
エージェント側はセキュリティが考慮されていないケースもある
clineは9月くらいまでローカルファイルにアクセスし放題だった
mcpの利用には細心の注意が必要
-->
## MCPのリスク

---
<!--
今まで書いたことをいい感じにまとめてほしい
メインの主張として、AIは有用だがリスクを理解する必要がある、信頼できるベンダーやサービスを選ぶことが重要であるってことを一番伝えたい
-->
## まとめ



