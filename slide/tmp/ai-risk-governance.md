---
marp: true
theme: myTheme
---

<!-- _class: lead -->
# AIのリスクとガバナンス

---
## 今回話す内容の全体像

- 今日は大きく **2つ** 話します
  1. **AIガバナンス**
     - 技術的な判断ではなく、最終的には経営判断になる
  2. **AIのリスク（3レイヤー）**
     - LLMベンダー
     - AIサービス
     - MCP
       - 各レイヤーごとに、何がリスクで何を判断すべきかを整理します

---
## AIガバナンス

- AIは**大きな恩恵**を生む一方、事故時の影響も大きい
- 現状は、周辺技術・ルール・倫理観の整備が追いついていない
- 重要なのは、リスクと恩恵の**トレードオフを明示的に決める**こと
- リスク整理は技術主導で進めるが、受容可否の最終判断は**経営判断**になる
- どんなリスクなら受け入れるかを先に決め、運用ルールに落とし込む

---
## AIのリスク

<div class="center">
  <div class="grid grid-3 with-arrows max-w">
    <div class="card">
      <h3>LLMベンダー</h3>
      <ul>
        <li>送信データの扱い</li>
        <li>学習利用・保持・閲覧</li>
      </ul>
    </div>
    <div class="card">
      <h3>AIサービス</h3>
      <ul>
        <li>権限と実行範囲</li>
        <li>誤操作・逸脱の影響</li>
      </ul>
    </div>
    <div class="card">
      <h3>MCP</h3>
      <ul>
        <li>拡張機能の信頼性</li>
        <li>悪意ある動作の混入</li>
      </ul>
    </div>
  </div>
</div>

---
## LLMベンダーのリスク

- LLMベンダーを使う = 社内データをベンダーへ送信する
- リスクは、ベンダー側のデータ取り扱い方針で決まる
  - 学習利用された場合、意図しない漏えいにつながる可能性
  - 送信後にベンダー内部で閲覧される可能性
- つまり、**「何を送ってよいか」** を先に定義する必要がある

---
## LLMベンダーで最低限決めること
<div class="center">
<div class="grid grid-2 max-w">
  <div class="card">
    <h3>データ境界</h3>
    <ul>
      <li>送信可：公開情報 / 一般技術情報</li>
      <li>要審査：社外秘 / 顧客情報</li>
      <li>送信不可：機密・個人情報・秘密鍵</li>
    </ul>
  </div>
  <div class="card">
    <h3>ベンダー選定</h3>
    <ul>
      <li>学習利用設定（オプトアウト可否）</li>
      <li>保持期間・削除ポリシー</li>
      <li>監査情報と契約条件の確認</li>
    </ul>
  </div>
</div>
</div>

---
## AIサービスとは

- LLMを使ったサービス全般を指す
  - チャット型（例: ChatGPT系）
  - エージェント型（例: 開発支援エージェント）
- 特にエージェントは、プロンプト応答だけでなく
  - ファイル操作
  - コマンド実行
  - 外部連携
  を通じて実世界へ影響できる

---
## AIサービスのリスク

- AIサービスは理論上、非常に広い操作範囲を持てる
- 開発エージェントではPC上のすべての情報へ到達できる可能性がある
- 設定次第では社内ネットワークへ影響し得る
- 重要なのは、
  - **最悪ケースは何か**
  - **それを監視・制御できるか**
  を事前に確認すること

---
## AIサービスで最低限決めること
<div class="center">
<div class="grid grid-3 max-w">
  <div class="card">
    <h3>権限</h3>
    <ul>
      <li>アクセス範囲を最小化</li>
      <li>不要な権限は与えない</li>
    </ul>
  </div>
  <div class="card">
    <h3>監視</h3>
    <ul>
      <li>実行ログを残す</li>
      <li>異常動作を検知する</li>
    </ul>
  </div>
  <div class="card">
    <h3>選定</h3>
    <ul>
      <li>運営主体の信頼性</li>
      <li>安全設計の透明性</li>
    </ul>
  </div>
</div>
</div>

---
## MCPのリスク

- MCPは有用だが、まだ発展途上の領域
- 悪意あるMCPとエージェントが組み合わさると、
  **実質的にマルウェアを導入した状態**に近づく
- 想定される挙動例
  - 外部通信で情報を持ち出す
  - 特定ディレクトリを削除する誘導
- エージェント側の実装成熟度にも差があり、注意が必要

---
## MCP利用時の注意点

<div class="center">
<div class="grid grid-2 max-w">
  <div class="card">
    <h3>MCP側の確認</h3>
    <ul>
      <li>提供元・更新頻度・公開情報</li>
      <li>要求権限と動作範囲の妥当性</li>
      <li>通信先・ログ出力の有無</li>
    </ul>
  </div>
  <div class="card">
    <h3>実行環境の防御</h3>
    <ul>
      <li>サンドボックス実行</li>
      <li>機密領域へのアクセス分離</li>
      <li>破壊的操作に手動承認を必須化</li>
    </ul>
  </div>
</div>
</div>

---
## まとめ

- AIは事業価値を生むが、リスクを理解しない導入は危険
- リスクは1つではなく、
  **LLMベンダー / AIサービス / MCP**で性質が異なる
- だからこそ、
  - 信頼できるベンダー・サービスを選ぶ
  - 送信データと権限を明確に制限する
  - 受容リスクを経営層が判断する
  ことが不可欠
- AI導入の成否は、モデル性能だけでなく**ガバナンス設計の質**で決まる
