---
marp: true
theme: myTheme
---
<!-- _class: lead -->
# AIセキュリティ入門

---
## AIガバナンス

- **リスクと恩恵のトレードオフを決めること**
  - 技術的にも倫理的にもリスクがある
- 技術判断ではなく **経営判断**
  - 使わなければ安全
  - 使わなければ競争力は落ちる
- リスクを理解し、受容できるかを判断する

---

## AIのリスク
業務で使うAIは、大きく3つのレイヤーに分けられる

1. LLMベンダー
2. AIサービス（エージェント含む）
3. MCP（拡張・実行レイヤー）

---

## 1. LLMベンダーのリスク

### 入力データが学習・改善に使われる可能性

- openAIを始め、LLMベンダーは「入力を完全に秘匿する」前提ではない
  - LLMの改善、保守運用に使う
  - 学習に使われると不特定多数に情報が漏れる可能性
  - 使われなかったとしても、openAIの内部で情報が閲覧される可能性

---

## LLMベンダーへの向き合い方
- 何を入力してよいかを決める必要がある
  - 業務情報、個人情報、機密情報など
  - 法令遵守の観点も含む
- オプトアウトをしても学習に使われないだけ
  - 内部での閲覧は防げない可能性が高い
- **信頼できるベンダーを選ぶことが重要**

---

## 2. AIサービス・エージェントのリスク

### 「できることが多すぎる」問題
- 複雑なことをやるには多くの権限が必要
  - claude codeであればターミナルにアクセスできるので、理論上サーバー内の全情報にアクセス可能
  - curlを使えば社内ネットワークにもアクセス可能
- 複数システムに横断アクセス
  - geminiだとgmail、カレンダー、ドライブなどに横断アクセス可能
- 意図せず非公開情報に触れる可能性
  - 意図しないコマンドの実行で非公開情報にアクセス
  - 複数の情報を組み合わせた結果個人が特定できるように

---
## AIサービスで起きやすい事故

- 意図しないデータアクセスで情報が横流し
  - セキュリティが考慮されていないAIサービスの利用
  - 悪意のあるAIサービスの利用
- どこから漏れたか追えない
  - AIサービスの監視は非常に難易度が高い
  - 完璧に動くを把握するのは困難
- 事故後に説明責任が取れない

---

## 必要なのは
- 信頼できるサービス
- **もしくは行動を制限できる仕組み**
  - これは発明が必要

---
## 3. MCPのリスク

### MCP = AIのプラグイン

- 多くはローカルにインストール
- 実行権限を持つソフトウェア
- 悪意あるMCPは **ウイルス同然**

---

## MCPが怖い理由

- 一度信頼すると、エージェント経由で影響
- エージェントのアクセス制御が甘いと情報は抜き放題
  - ちょっと前までclineはロールファイルアクセスし放題だった
  - cluade codeはmcp自作してないので不明

### 対応方針
- **信頼できるMCPのみ利用**
- 誰が信頼を判断するかを明確に

---

## まとめ

- AIは危険だから止める、ではない
- **使う前提で、壊れ方を設計する**
- 重要なのは
  - どこを信頼するか
  - どこまでを許容するか
  - それを誰が決めるか

